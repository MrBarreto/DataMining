{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from config import load_config\n",
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capturar_data_mapa(conn, table_name, linha):\n",
    "    cur = conn.cursor()\n",
    "    all_data = [] \n",
    "    try:\n",
    "        fetch_query = f'''\n",
    "        SELECT latitude::double precision, longitude::double precision\n",
    "        FROM {table_name}\n",
    "        WHERE linha='{linha}'\n",
    "        '''\n",
    "        cur.execute(fetch_query)\n",
    "        rows = cur.fetchall()\n",
    "        all_data.extend(rows)\n",
    "    except Exception as e:\n",
    "            print(f\"Erro ao executar a query na tabela {table_name}: {e}\")\n",
    "            conn.rollback()\n",
    "    else:\n",
    "         conn.commit()\n",
    "    cur.close()\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_dados_tabela(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        # Adicionar a coluna hour, se não existir\n",
    "        cur.execute(f\"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS hour INTEGER;\")\n",
    "        \n",
    "        # Atualizar a coluna hour com base no datahora\n",
    "        cur.execute(f\"UPDATE {table_name} SET hour = EXTRACT(HOUR FROM TO_TIMESTAMP(datahora / 1000));\")\n",
    "        \n",
    "        # Criar uma nova tabela filtrada\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {table_name}_filter AS\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "            WHERE hour BETWEEN 8 AND 22;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Remover a coluna hour das tabelas\n",
    "        cur.execute(f\"ALTER TABLE {table_name} DROP COLUMN hour;\")\n",
    "        cur.execute(f\"ALTER TABLE {table_name}_filter DROP COLUMN hour;\")\n",
    "        \n",
    "        # Commit das alterações\n",
    "        conn.commit()\n",
    "        print(f\"Alterações na tabela {table_name} foram comitadas com sucesso.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao limpar dados da tabela {table_name}: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_geom(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        # Adicionar a coluna geom se não existir\n",
    "        cur.execute(f\"\"\"\n",
    "            ALTER TABLE {table_name}_filter ADD COLUMN IF NOT EXISTS geom geography(Point, 4326);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Atualizar a coluna geom com os valores de longitude e latitude\n",
    "        cur.execute(f\"\"\"\n",
    "            UPDATE {table_name}_filter \n",
    "            SET geom = ST_SetSRID(ST_MakePoint(longitude::double precision, latitude::double precision), 4326);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Commit das alterações\n",
    "        conn.commit()\n",
    "        print(f\"Coluna geom criada e preenchida na tabela {table_name}_filter com sucesso.\")\n",
    "    except Exception as e:\n",
    "        # Rollback em caso de erro\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao atualizar a tabela {table_name}_filter: {e}\")\n",
    "    finally:\n",
    "        # Fechar o cursor\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}_filter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_linhas(table_name, linhas_de_interesse, conn):\n",
    "    cur = conn.cursor()\n",
    "    temp_table_name = table_name + '_intermediate'\n",
    "    linhas_str = ', '.join([f\"'{linha}'\" for linha in linhas_de_interesse])\n",
    "    try:\n",
    "        # Criar tabela intermediária filtrada\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {temp_table_name} AS\n",
    "            SELECT *\n",
    "            FROM {table_name}_filter\n",
    "            WHERE linha IN ({linhas_str});\n",
    "        \"\"\")\n",
    "        print(f\"Tabela intermediária {temp_table_name} criada com sucesso.\")\n",
    "        conn.commit()\n",
    "        print(f\"Alterações na tabela {temp_table_name} foram comitadas com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar a tabela intermediária {temp_table_name}: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {temp_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobrescreve_tabelas(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    temp_table_name = table_name + '_intermediate'\n",
    "    try:\n",
    "        # Verificar se a tabela temporária existe\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT FROM pg_tables\n",
    "                WHERE schemaname = 'public' AND tablename = '{temp_table_name}'\n",
    "            );\n",
    "        \"\"\")\n",
    "        exists = cur.fetchone()[0]\n",
    "\n",
    "        if exists:\n",
    "            # Excluir a tabela original\n",
    "            cur.execute(f\"DROP TABLE IF EXISTS {table_name}_filter;\")\n",
    "            # Renomear a tabela temporária para o nome original\n",
    "            cur.execute(f\"ALTER TABLE {temp_table_name} RENAME TO {table_name}_filter;\")\n",
    "            print(f\"Tabela {table_name}_filter sobrescrita com sucesso.\")\n",
    "            conn.commit()\n",
    "            print(f\"Tabela {table_name}_filter comitada com sucesso.\")\n",
    "        else:\n",
    "            print(f\"Tabela temporária {temp_table_name} não encontrada.\")\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao sobrescrever a tabela {table_name}_filter: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}_filter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margem_erro(coord1, coord2, radius=100):\n",
    "    return geodesic(coord1, coord2).meters <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(config):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    try:\n",
    "        # connecting to the PostgreSQL server\n",
    "        with psycopg2.connect(**config) as conn:\n",
    "            print('Connected to the PostgreSQL server.')\n",
    "            return conn\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL server.\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "conn = connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas_de_interesse = ['483', '864', '639', '3', '309', '774', '629', '371', '397', '100', '838', '315', '624', '388', '918', '665', '328', '497', '878', '355', '138', '606', '457', '550', '803', '917', '638', '2336', '399', '298', '867', '553', '565', '422', '756', '186012003', '292', '554', '634', '232', '415', '2803', '324', '852', '557', '759', '343', '779', '905', '108']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['dia_0105', 'dia_0205', 'dia_0305', 'dia_0405', 'dia_0505', 'dia_0605', 'dia_0705', 'dia_0805', 'dia_0905', 'dia_1005', 'dia_2504', 'dia_2604', 'dia_2704', 'dia_2804', 'dia_2904', 'dia_3004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for table in table_names:\\n    limpar_dados_tabela(table, conn)'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for table in table_names:\n",
    "    limpar_dados_tabela(table, conn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna geom criada e preenchida na tabela dia_0105_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0105_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0205_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0205_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0305_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0305_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0405_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0405_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0505_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0505_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0605_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0605_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0705_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0705_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0805_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0805_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_0905_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_0905_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_1005_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_1005_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_2504_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_2504_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_2604_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_2604_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_2704_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_2704_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_2804_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_2804_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_2904_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_2904_filter.\n",
      "Coluna geom criada e preenchida na tabela dia_3004_filter com sucesso.\n",
      "Cursor fechado para a tabela dia_3004_filter.\n"
     ]
    }
   ],
   "source": [
    "for table in table_names:\n",
    "    adicionar_geom(table, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela intermediária dia_0105_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0105_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0105_intermediate.\n",
      "Tabela dia_0105_filter sobrescrita com sucesso.\n",
      "Tabela dia_0105_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0105_filter.\n",
      "Tabela intermediária dia_0205_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0205_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0205_intermediate.\n",
      "Tabela dia_0205_filter sobrescrita com sucesso.\n",
      "Tabela dia_0205_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0205_filter.\n",
      "Tabela intermediária dia_0305_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0305_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0305_intermediate.\n",
      "Tabela dia_0305_filter sobrescrita com sucesso.\n",
      "Tabela dia_0305_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0305_filter.\n",
      "Tabela intermediária dia_0405_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0405_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0405_intermediate.\n",
      "Tabela dia_0405_filter sobrescrita com sucesso.\n",
      "Tabela dia_0405_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0405_filter.\n",
      "Tabela intermediária dia_0505_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0505_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0505_intermediate.\n",
      "Tabela dia_0505_filter sobrescrita com sucesso.\n",
      "Tabela dia_0505_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0505_filter.\n",
      "Tabela intermediária dia_0605_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0605_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0605_intermediate.\n",
      "Tabela dia_0605_filter sobrescrita com sucesso.\n",
      "Tabela dia_0605_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0605_filter.\n",
      "Tabela intermediária dia_0705_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0705_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0705_intermediate.\n",
      "Tabela dia_0705_filter sobrescrita com sucesso.\n",
      "Tabela dia_0705_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0705_filter.\n",
      "Tabela intermediária dia_0805_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0805_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0805_intermediate.\n",
      "Tabela dia_0805_filter sobrescrita com sucesso.\n",
      "Tabela dia_0805_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0805_filter.\n",
      "Tabela intermediária dia_0905_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_0905_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_0905_intermediate.\n",
      "Tabela dia_0905_filter sobrescrita com sucesso.\n",
      "Tabela dia_0905_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_0905_filter.\n",
      "Tabela intermediária dia_1005_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_1005_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_1005_intermediate.\n",
      "Tabela dia_1005_filter sobrescrita com sucesso.\n",
      "Tabela dia_1005_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_1005_filter.\n",
      "Tabela intermediária dia_2504_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_2504_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_2504_intermediate.\n",
      "Tabela dia_2504_filter sobrescrita com sucesso.\n",
      "Tabela dia_2504_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_2504_filter.\n",
      "Tabela intermediária dia_2604_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_2604_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_2604_intermediate.\n",
      "Tabela dia_2604_filter sobrescrita com sucesso.\n",
      "Tabela dia_2604_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_2604_filter.\n",
      "Tabela intermediária dia_2704_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_2704_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_2704_intermediate.\n",
      "Tabela dia_2704_filter sobrescrita com sucesso.\n",
      "Tabela dia_2704_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_2704_filter.\n",
      "Tabela intermediária dia_2804_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_2804_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_2804_intermediate.\n",
      "Tabela dia_2804_filter sobrescrita com sucesso.\n",
      "Tabela dia_2804_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_2804_filter.\n",
      "Tabela intermediária dia_2904_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_2904_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_2904_intermediate.\n",
      "Tabela dia_2904_filter sobrescrita com sucesso.\n",
      "Tabela dia_2904_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_2904_filter.\n",
      "Tabela intermediária dia_3004_intermediate criada com sucesso.\n",
      "Alterações na tabela dia_3004_intermediate foram comitadas com sucesso.\n",
      "Cursor fechado para a tabela dia_3004_intermediate.\n",
      "Tabela dia_3004_filter sobrescrita com sucesso.\n",
      "Tabela dia_3004_filter comitada com sucesso.\n",
      "Cursor fechado para a tabela dia_3004_filter.\n"
     ]
    }
   ],
   "source": [
    "for table in table_names:\n",
    "    filtra_linhas(table, linhas_de_interesse, conn)\n",
    "    sobrescreve_tabelas(table, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for linha in linhas_de_interesse:\\n    data = capturar_data_mapa(conn, \\'dia_2704_filter\\', linha)\\n    if data:\\n        avg_latitude = sum([d[0] for d in data]) / len(data)\\n        avg_longitude = sum([d[1] for d in data]) / len(data)\\n        m = folium.Map(location=[avg_latitude, avg_longitude], zoom_start=12)\\n        # Adicione os pontos ao mapa\\n        for lat, lon in data:\\n            folium.CircleMarker(location=[lat, lon], radius=1, color=\\'blue\\').add_to(m)\\n        output_path = os.path.join(f\\'trajetos/output_map_{linha}.html\\')\\n        m.save(output_path)\\n        print(f\"Mapa salvo em {output_path}\")'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for linha in linhas_de_interesse:\n",
    "    data = capturar_data_mapa(conn, 'dia_2704_filter', linha)\n",
    "    if data:\n",
    "        avg_latitude = sum([d[0] for d in data]) / len(data)\n",
    "        avg_longitude = sum([d[1] for d in data]) / len(data)\n",
    "        m = folium.Map(location=[avg_latitude, avg_longitude], zoom_start=12)\n",
    "        # Adicione os pontos ao mapa\n",
    "        for lat, lon in data:\n",
    "            folium.CircleMarker(location=[lat, lon], radius=1, color='blue').add_to(m)\n",
    "        output_path = os.path.join(f'trajetos/output_map_{linha}.html')\n",
    "        m.save(output_path)\n",
    "        print(f\"Mapa salvo em {output_path}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_de_parada = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH ordered_points AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n",
    "        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n",
    "        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n",
    "    FROM dia_2704_filter\n",
    "),\n",
    "same_position_periods AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n",
    "        CASE \n",
    "            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n",
    "            ELSE 0\n",
    "        END AS is_stationary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n",
    "    FROM ordered_points\n",
    "),\n",
    "stationary_groups AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        duration,\n",
    "        is_stationary,\n",
    "        grp\n",
    "    FROM same_position_periods\n",
    "    WHERE is_stationary = 1\n",
    ")\n",
    "SELECT\n",
    "    ordem,\n",
    "    linha,\n",
    "    MIN(prev_datahora_ts) AS start_time,\n",
    "    MAX(datahora_ts) AS end_time,\n",
    "    SUM(duration) AS total_duration,\n",
    "    ST_X(geom::geometry) AS longitude,\n",
    "    ST_Y(geom::geometry) AS latitude,\n",
    "    grp\n",
    "FROM stationary_groups\n",
    "GROUP BY ordem, linha, grp, geom\n",
    "HAVING SUM(duration) >= 600; -- 10 minutes in seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4799/1168034203.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nWITH ordered_points AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n    FROM dia_2704_filter\n),\nsame_position_periods AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        datahora_ts,\n        prev_datahora_ts,\n        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n        CASE \n            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n            ELSE 0\n        END AS is_stationary,\n        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n    FROM ordered_points\n),\nstationary_groups AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        datahora_ts,\n        prev_datahora_ts,\n        duration,\n        is_stationary,\n        grp\n    FROM same_position_periods\n    WHERE is_stationary = 1\n)\nSELECT\n    ordem,\n    linha,\n    MIN(prev_datahora_ts) AS start_time,\n    MAX(datahora_ts) AS end_time,\n    SUM(duration) AS total_duration,\n    ST_X(geom::geometry) AS longitude,\n    ST_Y(geom::geometry) AS latitude,\n    grp\nFROM stationary_groups\nGROUP BY ordem, linha, grp, geom\nHAVING SUM(duration) >= 600; -- 10 minutes in seconds\n': relation \"dia_2704_filter\" does not exist\nLINE 11:     FROM dia_2704_filter\n                  ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2262\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: relation \"dia_2704_filter\" does not exist\nLINE 11:     FROM dia_2704_filter\n                  ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, conn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:654\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    655\u001b[0m             sql,\n\u001b[1;32m    656\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    657\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    658\u001b[0m             coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    659\u001b[0m             parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    660\u001b[0m             chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    661\u001b[0m             dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    662\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    663\u001b[0m         )\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2317\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2326\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2327\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nWITH ordered_points AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n    FROM dia_2704_filter\n),\nsame_position_periods AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        datahora_ts,\n        prev_datahora_ts,\n        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n        CASE \n            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n            ELSE 0\n        END AS is_stationary,\n        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n    FROM ordered_points\n),\nstationary_groups AS (\n    SELECT\n        ordem,\n        linha,\n        geom,\n        datahora_ts,\n        prev_datahora_ts,\n        duration,\n        is_stationary,\n        grp\n    FROM same_position_periods\n    WHERE is_stationary = 1\n)\nSELECT\n    ordem,\n    linha,\n    MIN(prev_datahora_ts) AS start_time,\n    MAX(datahora_ts) AS end_time,\n    SUM(duration) AS total_duration,\n    ST_X(geom::geometry) AS longitude,\n    ST_Y(geom::geometry) AS latitude,\n    grp\nFROM stationary_groups\nGROUP BY ordem, linha, grp, geom\nHAVING SUM(duration) >= 600; -- 10 minutes in seconds\n': relation \"dia_2704_filter\" does not exist\nLINE 11:     FROM dia_2704_filter\n                  ^\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_unique.loc[df_unique['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        encontrado = False\n",
    "        if row['total_duration'] > 24000:\n",
    "            continue\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos, ponto):\n",
    "                encontrado = True\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append(ponto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 483 tem 5 paradas.\n",
      "A 864 tem 5 paradas.\n",
      "A 639 tem 6 paradas.\n",
      "A 3 tem 2 paradas.\n",
      "A 309 tem 5 paradas.\n",
      "A 774 tem 2 paradas.\n",
      "A 629 tem 3 paradas.\n",
      "A 371 tem 1 paradas.\n",
      "A 397 tem 3 paradas.\n",
      "A 100 tem 7 paradas.\n",
      "A 838 tem 4 paradas.\n",
      "A 315 tem 11 paradas.\n",
      "A 624 tem 3 paradas.\n",
      "A 388 tem 2 paradas.\n",
      "A 918 tem 5 paradas.\n",
      "A 665 tem 14 paradas.\n",
      "A 328 tem 4 paradas.\n",
      "A 497 tem 4 paradas.\n",
      "A 878 tem 3 paradas.\n",
      "A 355 tem 4 paradas.\n",
      "A 138 tem 0 paradas.\n",
      "A 606 tem 5 paradas.\n",
      "A 457 tem 7 paradas.\n",
      "A 550 tem 5 paradas.\n",
      "A 803 tem 4 paradas.\n",
      "A 917 tem 3 paradas.\n",
      "A 638 tem 3 paradas.\n",
      "A 2336 tem 5 paradas.\n",
      "A 399 tem 6 paradas.\n",
      "A 298 tem 6 paradas.\n",
      "A 867 tem 4 paradas.\n",
      "A 553 tem 4 paradas.\n",
      "A 565 tem 4 paradas.\n",
      "A 422 tem 3 paradas.\n",
      "A 756 tem 6 paradas.\n",
      "A 186012003 tem 0 paradas.\n",
      "A 292 tem 6 paradas.\n",
      "A 554 tem 2 paradas.\n",
      "A 634 tem 2 paradas.\n",
      "A 232 tem 6 paradas.\n",
      "A 415 tem 5 paradas.\n",
      "A 2803 tem 5 paradas.\n",
      "A 324 tem 4 paradas.\n",
      "A 852 tem 2 paradas.\n",
      "A 557 tem 8 paradas.\n",
      "A 759 tem 2 paradas.\n",
      "A 343 tem 3 paradas.\n",
      "A 779 tem 4 paradas.\n",
      "A 905 tem 3 paradas.\n",
      "A 108 tem 3 paradas.\n"
     ]
    }
   ],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    tamanho = len(pontos_de_parada[linha])\n",
    "    print(f\"A {linha} tem {tamanho} paradas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
