{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from config import load_config\n",
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic, distance\n",
    "import numpy as np\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import shapely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capturar_data_mapa(conn, table_name, linha):\n",
    "    cur = conn.cursor()\n",
    "    all_data = [] \n",
    "    try:\n",
    "        fetch_query = f'''\n",
    "        SELECT latitude::double precision, longitude::double precision\n",
    "        FROM {table_name}\n",
    "        WHERE linha='{linha}'\n",
    "        '''\n",
    "        cur.execute(fetch_query)\n",
    "        rows = cur.fetchall()\n",
    "        all_data.extend(rows)\n",
    "    except Exception as e:\n",
    "            print(f\"Erro ao executar a query na tabela {table_name}: {e}\")\n",
    "            conn.rollback()\n",
    "    else:\n",
    "         conn.commit()\n",
    "    cur.close()\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_dados_tabela(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        # Adicionar a coluna hour, se não existir\n",
    "        cur.execute(f\"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS hour INTEGER;\")\n",
    "        \n",
    "        # Atualizar a coluna hour com base no datahora\n",
    "        cur.execute(f\"UPDATE {table_name} SET hour = EXTRACT(HOUR FROM TO_TIMESTAMP(datahora / 1000));\")\n",
    "        \n",
    "        # Criar uma nova tabela filtrada\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {table_name}_filter AS\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "            WHERE hour BETWEEN 8 AND 22;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Remover a coluna hour das tabelas\n",
    "        cur.execute(f\"ALTER TABLE {table_name} DROP COLUMN hour;\")\n",
    "        cur.execute(f\"ALTER TABLE {table_name}_filter DROP COLUMN hour;\")\n",
    "        \n",
    "        # Commit das alterações\n",
    "        conn.commit()\n",
    "        print(f\"Alterações na tabela {table_name} foram comitadas com sucesso.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao limpar dados da tabela {table_name}: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_geom(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        # Adicionar a coluna geom se não existir\n",
    "        cur.execute(f\"\"\"\n",
    "            ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS geom geography(Point, 4326);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Atualizar a coluna geom com os valores de longitude e latitude\n",
    "        cur.execute(f\"\"\"\n",
    "            UPDATE {table_name}\n",
    "            SET geom = ST_SetSRID(ST_MakePoint(longitude::double precision, latitude::double precision), 4326);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Commit das alterações\n",
    "        conn.commit()\n",
    "        print(f\"Coluna geom criada e preenchida na tabela {table_name}_filter com sucesso.\")\n",
    "    except Exception as e:\n",
    "        # Rollback em caso de erro\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao atualizar a tabela {table_name}_filter: {e}\")\n",
    "    finally:\n",
    "        # Fechar o cursor\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}_filter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_linhas(table_name, linhas_de_interesse, conn):\n",
    "    cur = conn.cursor()\n",
    "    temp_table_name = table_name + '_intermediate'\n",
    "    linhas_str = ', '.join([f\"'{linha}'\" for linha in linhas_de_interesse])\n",
    "    try:\n",
    "        # Criar tabela intermediária filtrada\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE {temp_table_name} AS\n",
    "            SELECT *\n",
    "            FROM {table_name}_filter\n",
    "            WHERE linha IN ({linhas_str});\n",
    "        \"\"\")\n",
    "        print(f\"Tabela intermediária {temp_table_name} criada com sucesso.\")\n",
    "        conn.commit()\n",
    "        print(f\"Alterações na tabela {temp_table_name} foram comitadas com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar a tabela intermediária {temp_table_name}: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {temp_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobrescreve_tabelas(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    temp_table_name = table_name + '_intermediate'\n",
    "    try:\n",
    "        # Verificar se a tabela temporária existe\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT FROM pg_tables\n",
    "                WHERE schemaname = 'public' AND tablename = '{temp_table_name}'\n",
    "            );\n",
    "        \"\"\")\n",
    "        exists = cur.fetchone()[0]\n",
    "\n",
    "        if exists:\n",
    "            # Excluir a tabela original\n",
    "            cur.execute(f\"DROP TABLE IF EXISTS {table_name}_filter;\")\n",
    "            # Renomear a tabela temporária para o nome original\n",
    "            cur.execute(f\"ALTER TABLE {temp_table_name} RENAME TO {table_name}_filter;\")\n",
    "            print(f\"Tabela {table_name}_filter sobrescrita com sucesso.\")\n",
    "            conn.commit()\n",
    "            print(f\"Tabela {table_name}_filter comitada com sucesso.\")\n",
    "        else:\n",
    "            print(f\"Tabela temporária {temp_table_name} não encontrada.\")\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao sobrescrever a tabela {table_name}_filter: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        print(f\"Cursor fechado para a tabela {table_name}_filter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margem_erro(coord1, coord2, radius=100):\n",
    "    return geodesic(coord1, coord2).meters <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_tabela_destino(conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS combined_table_all AS\n",
    "            SELECT * FROM dia_0105 WHERE 1=0;\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "        print(\"Tabela de destino 'combined_table_all' criada com sucesso.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao criar a tabela de destino: {e}\")\n",
    "    finally:\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_dados(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(f\"INSERT INTO combined_table_all SELECT * FROM {table_name};\")\n",
    "        conn.commit()\n",
    "        print(f\"Dados inseridos na tabela 'combined_table' a partir de '{table_name}' com sucesso.\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Erro ao inserir dados da tabela {table_name}: {e}\")\n",
    "    finally:\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(config):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    try:\n",
    "        # connecting to the PostgreSQL server\n",
    "        with psycopg2.connect(**config) as conn:\n",
    "            print('Connected to the PostgreSQL server.')\n",
    "            return conn\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL server.\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "conn = connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas_de_interesse = ['483', '864', '639', '3', '309', '774', '629', '371', '397', '100', '838', '315', '624', '388', '918', '665', '328', '497', '878', '355', '138', '606', '457', '550', '803', '917', '638', '2336', '399', '298', '867', '553', '565', '422', '756', '186012003', '292', '554', '634', '232', '415', '2803', '324', '852', '557', '759', '343', '779', '905', '108']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['dia_0105', 'dia_0205', 'dia_0305', 'dia_0405', 'dia_0505', 'dia_0605', 'dia_0705', 'dia_0805', 'dia_0905', 'dia_1005', 'dia_2504', 'dia_2604', 'dia_2704', 'dia_2804', 'dia_2904', 'dia_3004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for table in table_names:\\n    limpar_dados_tabela(table, conn)'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for table in table_names:\n",
    "    limpar_dados_tabela(table, conn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for table in table_names:\n",
    "    adicionar_geom(table, conn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for table in table_names:\n",
    "    filtra_linhas(table, linhas_de_interesse, conn)\n",
    "    sobrescreve_tabelas(table, conn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for linha in linhas_de_interesse:\\n    data = capturar_data_mapa(conn, \\'dia_2704_filter\\', linha)\\n    if data:\\n        avg_latitude = sum([d[0] for d in data]) / len(data)\\n        avg_longitude = sum([d[1] for d in data]) / len(data)\\n        m = folium.Map(location=[avg_latitude, avg_longitude], zoom_start=12)\\n        # Adicione os pontos ao mapa\\n        for lat, lon in data:\\n            folium.CircleMarker(location=[lat, lon], radius=1, color=\\'blue\\').add_to(m)\\n        output_path = os.path.join(f\\'trajetos/output_map_{linha}.html\\')\\n        m.save(output_path)\\n        print(f\"Mapa salvo em {output_path}\")'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for linha in linhas_de_interesse:\n",
    "    data = capturar_data_mapa(conn, 'dia_2704_filter', linha)\n",
    "    if data:\n",
    "        avg_latitude = sum([d[0] for d in data]) / len(data)\n",
    "        avg_longitude = sum([d[1] for d in data]) / len(data)\n",
    "        m = folium.Map(location=[avg_latitude, avg_longitude], zoom_start=12)\n",
    "        # Adicione os pontos ao mapa\n",
    "        for lat, lon in data:\n",
    "            folium.CircleMarker(location=[lat, lon], radius=1, color='blue').add_to(m)\n",
    "        output_path = os.path.join(f'trajetos/output_map_{linha}.html')\n",
    "        m.save(output_path)\n",
    "        print(f\"Mapa salvo em {output_path}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"criar_tabela_destino(conn)\n",
    "for table in table_names:\n",
    "    inserir_dados(table, conn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH ordered_points AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n",
    "        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n",
    "        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n",
    "    FROM combined_table\n",
    "),\n",
    "same_position_periods AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n",
    "        CASE \n",
    "            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n",
    "            ELSE 0\n",
    "        END AS is_stationary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n",
    "    FROM ordered_points\n",
    "),\n",
    "stationary_groups AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        duration,\n",
    "        is_stationary,\n",
    "        grp\n",
    "    FROM same_position_periods\n",
    "    WHERE is_stationary = 1\n",
    ")\n",
    "SELECT\n",
    "    ordem,\n",
    "    linha,\n",
    "    MIN(prev_datahora_ts) AS start_time,\n",
    "    MAX(datahora_ts) AS end_time,\n",
    "    SUM(duration) AS total_duration,\n",
    "    ST_X(geom::geometry) AS longitude,\n",
    "    ST_Y(geom::geometry) AS latitude,\n",
    "    grp\n",
    "FROM stationary_groups\n",
    "GROUP BY ordem, linha, grp, geom\n",
    "HAVING SUM(duration) >= 600; -- 10 minutes in seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7403/1168034203.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_unique.loc[df_unique['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        if margem_erro(ponto, pontos_garagem[linha]):\n",
    "             continue\n",
    "        encontrado = False\n",
    "        if row['total_duration'] > 2400:\n",
    "            continue\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos[0], ponto):\n",
    "                encontrado = True\n",
    "                pontos[1] += 1\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append([ponto, 1])\n",
    "for linha in pontos_de_parada.keys():\n",
    "        pontos_de_parada[linha] = sorted(pontos_de_parada[linha], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "397\n",
    "388\n",
    "759\n",
    "138 \n",
    "tiveram resultados inconclusivos, adicionarei manualmente os pontos finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada_linha = pontos_de_parada[linha]\n",
    "    if len(pontos_de_parada[linha]) > 0:\n",
    "        if (pontos_de_parada_linha[1][1] - pontos_de_parada_linha[2][1]) < 0.2*pontos_de_parada_linha[2][1]:\n",
    "            d2 = geodesic(pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]).meters\n",
    "            d3 = geodesic(pontos_de_parada_linha[0][0], pontos_de_parada_linha[2][0]).meters\n",
    "            if d2 > d3:\n",
    "                pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]]\n",
    "            else:\n",
    "                pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[2][0]]\n",
    "        else:\n",
    "            pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_finais['397'] = [(-22.90202, -43.55532), (-22.90121, -43.17778)]\n",
    "pontos_finais['388'] = [(-22.93554, -43.65626), (-22.90121, -43.17778)]\n",
    "pontos_finais['759'] = [(-22.93554, -43.65626), (-22.83152, -43.34393)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_tabela_destino(conn)\n",
    "for table in table_names:\n",
    "    inserir_dados(table, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_garagem = \"\"\"\n",
    "WITH ordered_points AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n",
    "        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n",
    "        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n",
    "    FROM combined_table_all\n",
    "),\n",
    "same_position_periods AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n",
    "        CASE \n",
    "            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n",
    "            ELSE 0\n",
    "        END AS is_stationary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n",
    "    FROM ordered_points\n",
    "),\n",
    "stationary_groups AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        duration,\n",
    "        is_stationary,\n",
    "        grp\n",
    "    FROM same_position_periods\n",
    "    WHERE is_stationary = 1\n",
    ")\n",
    "SELECT\n",
    "    ordem,\n",
    "    linha,\n",
    "    MIN(prev_datahora_ts) AS start_time,\n",
    "    MAX(datahora_ts) AS end_time,\n",
    "    SUM(duration) AS total_duration,\n",
    "    ST_X(geom::geometry) AS longitude,\n",
    "    ST_Y(geom::geometry) AS latitude,\n",
    "    grp\n",
    "FROM stationary_groups\n",
    "WHERE EXTRACT(HOUR FROM datahora_ts) >= 22 OR EXTRACT(HOUR FROM datahora_ts) < 5\n",
    "GROUP BY ordem, linha, grp, geom\n",
    "HAVING SUM(duration) >= 10800; -- 10 minutes in seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7675/3362709450.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_garagem = pd.read_sql(query_garagem, conn)\n"
     ]
    }
   ],
   "source": [
    "df_garagem = pd.read_sql(query_garagem, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_garagem = df_garagem.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_de_parada = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_garagem.loc[df_garagem['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        encontrado = False\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos[0], ponto, radius=300):\n",
    "                encontrado = True\n",
    "                pontos[1] += 1\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append([ponto, 1])\n",
    "for linha in pontos_de_parada.keys():\n",
    "        pontos_de_parada[linha] = sorted(pontos_de_parada[linha], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in pontos_de_parada.keys():\n",
    "    print(f\"{linha} {pontos_de_parada[linha]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "759, 388 não apresentaram resultados conclusivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_garagem = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_garagem_linha = pontos_de_parada[linha]\n",
    "    if len(pontos_de_parada[linha]) > 0:\n",
    "        pontos_garagem[linha] = pontos_de_garagem_linha[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in pontos_garagem.keys():\n",
    "    print(f\"{linha} {pontos_garagem[linha]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_garagem = pd.read_sql(query_garagem, conn)\n",
    "df_garagem = df_garagem.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_de_parada = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_garagem.loc[df_garagem['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        encontrado = False\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos[0], ponto, radius=300):\n",
    "                encontrado = True\n",
    "                pontos[1] += 1\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append([ponto, 1])\n",
    "for linha in pontos_de_parada.keys():\n",
    "        pontos_de_parada[linha] = sorted(pontos_de_parada[linha], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in pontos_de_parada.keys():\n",
    "    print(f\"{linha} {pontos_de_parada[linha]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_garagem['759'] = (-22.93569, -43.65591)\n",
    "pontos_garagem['388'] = (-22.93543, -43.65633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = 'dicionarios.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo, 'w') as f:\n",
    "    json.dump({'dicionario1': pontos_finais, 'dicionario2': pontos_garagem}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo, 'r') as f:\n",
    "    dados = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_finais = dados['dicionario1']\n",
    "pontos_garagem = dados['dicionario2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando tabelas para os dias de semana e fins de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias_da_semana = ['dia_2504_filter', 'dia_2604_filter', 'dia_2904_filter', 'dia_3004_filter', 'dia_0105_filter', 'dia_0205_filter', 'dia_0305_filter', 'dia_0605_filter', 'dia_0705_filter', 'dia_0805_filter', 'dia_0905_filter', 'dia_1005_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fins_de_semana = ['dia_2704_filter', 'dia_2804_filter', 'dia_0405_filter', 'dia_0505_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_dia_da_semana(nome_tabela):\n",
    "    data_str = nome_tabela.split('_')[1]\n",
    "    data = pd.to_datetime(f\"2024-{data_str[2:]}-{data_str[:2]}\")\n",
    "    return data.day_name()\n",
    "engine = create_engine('postgresql+psycopg2://savio:190876@localhost:5432/t3')\n",
    "for tabela in dias_da_semana:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabela}\", conn)\n",
    "    df['dia_da_semana'] = obter_dia_da_semana(tabela)\n",
    "    df.to_sql('dias_uteis_combinado', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tabela in fins_de_semana:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabela}\", conn)\n",
    "    df['dia_da_semana'] = obter_dia_da_semana(tabela)\n",
    "    df.to_sql('fds_combinado', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando uma tabela composta apenas pela madrugada dos fins de semana, onde a chance dos ônibus estarem na garagem é altíssima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garagens e pontos finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela de destino 'combined_table_all' criada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "criar_tabela_destino(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4588/589359576.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {tabela}\", conn)\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('postgresql+psycopg2://savio:190876@localhost:5432/t3')\n",
    "for tabela in table_names:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabela}\", conn)\n",
    "    df.to_sql('combined_table_all', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_garagem_madrugada = \"\"\"\n",
    "WITH ordered_points AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n",
    "        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n",
    "        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n",
    "    FROM combined_table_all\n",
    "),\n",
    "same_position_periods AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n",
    "        CASE \n",
    "            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n",
    "            ELSE 0\n",
    "        END AS is_stationary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n",
    "    FROM ordered_points\n",
    "),\n",
    "stationary_groups AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        duration,\n",
    "        is_stationary,\n",
    "        grp\n",
    "    FROM same_position_periods\n",
    "    WHERE is_stationary = 1\n",
    ")\n",
    "SELECT\n",
    "    ordem,\n",
    "    linha,\n",
    "    MIN(prev_datahora_ts) AS start_time,\n",
    "    MAX(datahora_ts) AS end_time,\n",
    "    SUM(duration) AS total_duration,\n",
    "    ST_X(geom::geometry) AS longitude,\n",
    "    ST_Y(geom::geometry) AS latitude,\n",
    "    grp\n",
    "FROM stationary_groups\n",
    "WHERE EXTRACT(HOUR FROM datahora_ts) >= 22 OR EXTRACT(HOUR FROM datahora_ts) < 5\n",
    "GROUP BY ordem, linha, grp, geom\n",
    "HAVING SUM(duration) >= 10800; -- 3 horas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4588/3718869355.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_garagem = pd.read_sql(query_garagem_madrugada, conn)\n"
     ]
    }
   ],
   "source": [
    "df_garagem = pd.read_sql(query_garagem_madrugada, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_garagem = df_garagem.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_de_parada = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_garagem.loc[df_garagem['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        encontrado = False\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos[0], ponto, radius=300):\n",
    "                encontrado = True\n",
    "                pontos[1] += 1\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append([ponto, 1])\n",
    "for linha in pontos_de_parada.keys():\n",
    "        pontos_de_parada[linha] = sorted(pontos_de_parada[linha], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483 [[(-22.80418, -43.31023), 103]]\n",
      "864 [[(-22.89368, -43.53259), 110], [(-22.84149, -43.25392), 2]]\n",
      "639 [[(-22.81763, -43.30176), 256]]\n",
      "3 [[(-22.88342, -43.49536), 222], [(-22.93548, -43.6565), 1]]\n",
      "309 [[(-22.87509, -43.24074), 334]]\n",
      "774 [[(-22.81756, -43.3016), 103], [(-22.84353, -43.24857), 1]]\n",
      "629 [[(-22.81775, -43.30167), 212], [(-22.84388, -43.24839), 1], [(-22.75517, -43.2938), 1]]\n",
      "371 [[(-22.87744, -43.36824), 24]]\n",
      "397 []\n",
      "100 [[(-22.88907, -43.29319), 231], [(-22.8745, -43.24212), 68], [(-22.84134, -43.25389), 4]]\n",
      "838 [[(-22.89399, -43.5327), 47]]\n",
      "315 [[(-22.87549, -43.24131), 109], [(-22.95217, -43.34944), 23], [(-22.81696, -43.30177), 8], [(-22.86062, -43.35616), 2]]\n",
      "624 [[(-22.87622, -43.36805), 21]]\n",
      "388 [[(-22.90154, -43.18066), 1], [(-22.93159, -43.6558), 1]]\n",
      "918 [[(-22.89523, -43.53366), 52], [(-22.84269, -43.25409), 1]]\n",
      "665 [[(-22.85928, -43.37079), 74], [(-22.81706, -43.39373), 45], [(-22.79242, -43.29449), 41], [(-22.81425, -43.38256), 8], [(-22.80611, -43.3633), 1], [(-22.84344, -43.24859), 1]]\n",
      "328 [[(-22.81515, -43.18753), 112]]\n",
      "497 [[(-22.80449, -43.30967), 60]]\n",
      "878 [[(-22.88064, -43.35695), 74], [(-22.87594, -43.41995), 1]]\n",
      "355 [[(-22.81683, -43.3015), 62], [(-22.86056, -43.35523), 29], [(-22.84366, -43.24862), 1]]\n",
      "138 []\n",
      "606 [[(-22.90259, -43.29907), 3]]\n",
      "457 [[(-22.88888, -43.29289), 123], [(-22.86871, -43.29263), 36], [(-22.81585, -43.39481), 17]]\n",
      "550 [[(-22.94975, -43.3482), 223], [(-22.95247, -43.34809), 1]]\n",
      "803 [[(-22.87612, -43.41912), 34], [(-22.88062, -43.35717), 4], [(-22.93558, -43.37196), 1]]\n",
      "917 [[(-22.87654, -43.36839), 27]]\n",
      "638 [[(-22.86042, -43.356), 145]]\n",
      "2336 [[(-22.91719, -43.6077), 61], [(-22.90241, -43.56149), 1], [(-22.89179, -43.21609), 1]]\n",
      "399 [[(-22.81743, -43.39355), 79], [(-22.81438, -43.38252), 17]]\n",
      "298 [[(-22.8162, -43.39447), 109], [(-22.81503, -43.38207), 2], [(-22.90555, -43.1735), 1]]\n",
      "867 [[(-22.89435, -43.53227), 25]]\n",
      "553 [[(-22.95321, -43.34991), 63], [(-22.87537, -43.24154), 1]]\n",
      "565 [[(-22.95077, -43.34814), 131], [(-22.8807, -43.358), 1]]\n",
      "422 [[(-22.88955, -43.29165), 218]]\n",
      "756 [[(-22.87659, -43.41991), 20], [(-22.87928, -43.35704), 1]]\n",
      "186012003 []\n",
      "292 [[(-22.86867, -43.29274), 100], [(-22.81799, -43.39303), 37], [(-22.81672, -43.30158), 31], [(-22.81458, -43.38233), 6]]\n",
      "554 [[(-22.95263, -43.34921), 44]]\n",
      "634 [[(-22.81524, -43.18743), 88]]\n",
      "232 [[(-22.90244, -43.29907), 1]]\n",
      "415 [[(-22.92992, -43.2537), 220], [(-22.84267, -43.25432), 1]]\n",
      "2803 [[(-22.89372, -43.53196), 65]]\n",
      "324 [[(-22.81515, -43.18877), 113]]\n",
      "852 [[(-22.89473, -43.5338), 25]]\n",
      "557 [[(-22.94995, -43.34814), 96], [(-22.95283, -43.34921), 1]]\n",
      "759 [[(-22.93558, -43.65622), 1]]\n",
      "343 [[(-22.95138, -43.34891), 78]]\n",
      "779 [[(-22.81658, -43.39421), 72], [(-22.81454, -43.38231), 15]]\n",
      "905 [[(-22.81685, -43.30169), 105]]\n",
      "108 [[(-22.87523, -43.24119), 119]]\n"
     ]
    }
   ],
   "source": [
    "for linha in pontos_de_parada.keys():\n",
    "    print(f\"{linha} {pontos_de_parada[linha]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "186012003 e 138 não existem // \n",
    "759, 232, 606, 388, 397 não obtiveram resultados satisfatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_garagem = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_garagem_linha = pontos_de_parada[linha]\n",
    "    if len(pontos_de_parada[linha]) > 0:\n",
    "        pontos_garagem[linha] = pontos_de_garagem_linha[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos_garagem['759'] = (-22.93569, -43.65591)\n",
    "pontos_garagem['388'] = (-22.93543, -43.65633)\n",
    "pontos_garagem['397'] = (-22.88320, -43.49516)\n",
    "pontos_garagem['606'] = (-22.90222, -43.29847)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_garagens = 'pontos_garagem.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo_garagens, 'w') as f:\n",
    "    json.dump({'dicionario1': pontos_garagem}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pontofinal = \"\"\"\n",
    "WITH ordered_points AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        TO_TIMESTAMP(datahora / 1000) AS datahora_ts,\n",
    "        LAG(TO_TIMESTAMP(datahora / 1000)) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_datahora_ts,\n",
    "        LAG(geom) OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS prev_geom,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY TO_TIMESTAMP(datahora / 1000)) AS rn\n",
    "    FROM combined_table\n",
    "),\n",
    "same_position_periods AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        EXTRACT(EPOCH FROM (datahora_ts - prev_datahora_ts)) AS duration,\n",
    "        CASE \n",
    "            WHEN ST_DWithin(geom, prev_geom, 15) THEN 1\n",
    "            ELSE 0\n",
    "        END AS is_stationary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem ORDER BY datahora_ts) - \n",
    "        ROW_NUMBER() OVER (PARTITION BY ordem, CASE WHEN ST_DWithin(geom, prev_geom, 15) THEN 1 ELSE 0 END ORDER BY datahora_ts) AS grp\n",
    "    FROM ordered_points\n",
    "),\n",
    "stationary_groups AS (\n",
    "    SELECT\n",
    "        ordem,\n",
    "        linha,\n",
    "        geom,\n",
    "        datahora_ts,\n",
    "        prev_datahora_ts,\n",
    "        duration,\n",
    "        is_stationary,\n",
    "        grp\n",
    "    FROM same_position_periods\n",
    "    WHERE is_stationary = 1\n",
    ")\n",
    "SELECT\n",
    "    ordem,\n",
    "    linha,\n",
    "    MIN(prev_datahora_ts) AS start_time,\n",
    "    MAX(datahora_ts) AS end_time,\n",
    "    SUM(duration) AS total_duration,\n",
    "    ST_X(geom::geometry) AS longitude,\n",
    "    ST_Y(geom::geometry) AS latitude,\n",
    "    grp\n",
    "FROM stationary_groups\n",
    "GROUP BY ordem, linha, grp, geom\n",
    "HAVING SUM(duration) >= 600; -- 10 minutes in seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4588/2110546385.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pf = pd.read_sql(query_pontofinal, conn)\n"
     ]
    }
   ],
   "source": [
    "df_pf = pd.read_sql(query_pontofinal, conn)\n",
    "df_pf = df_pf.drop_duplicates(subset=['grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada[linha]=[]\n",
    "    for _, row in df_unique.loc[df_unique['linha'] == linha].iterrows():\n",
    "        lat, lon = row['latitude'], row['longitude']\n",
    "        ponto = (lat, lon)\n",
    "        if margem_erro(ponto, pontos_garagem[linha]):\n",
    "             continue\n",
    "        encontrado = False\n",
    "        if row['total_duration'] > 2400:\n",
    "            continue\n",
    "        for pontos in pontos_de_parada[linha]:\n",
    "            if margem_erro(pontos[0], ponto):\n",
    "                encontrado = True\n",
    "                pontos[1] += 1\n",
    "                break\n",
    "        if not encontrado:\n",
    "            pontos_de_parada[linha].append([ponto, 1])\n",
    "for linha in pontos_de_parada.keys():\n",
    "        pontos_de_parada[linha] = sorted(pontos_de_parada[linha], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in linhas_de_interesse:\n",
    "    pontos_de_parada_linha = pontos_de_parada[linha]\n",
    "    if len(pontos_de_parada[linha]) > 0:\n",
    "        if (pontos_de_parada_linha[1][1] - pontos_de_parada_linha[2][1]) < 0.2*pontos_de_parada_linha[2][1]:\n",
    "            d2 = geodesic(pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]).meters\n",
    "            d3 = geodesic(pontos_de_parada_linha[0][0], pontos_de_parada_linha[2][0]).meters\n",
    "            if d2 > d3:\n",
    "                pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]]\n",
    "            else:\n",
    "                pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[2][0]]\n",
    "        else:\n",
    "            pontos_finais[linha] = [pontos_de_parada_linha[0][0], pontos_de_parada_linha[1][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14735/1545976685.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  teste = pd.read_sql(f\"SELECT * FROM dias_uteis_combinado WHERE linha = '315'\", conn)\n"
     ]
    }
   ],
   "source": [
    "teste = pd.read_sql(f\"SELECT * FROM dias_uteis_combinado WHERE linha = '315'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['geometry'] = teste['geom'].apply(wkb.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(teste, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ordem</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datahora</th>\n",
       "      <th>velocidade</th>\n",
       "      <th>linha</th>\n",
       "      <th>datahoraenvio</th>\n",
       "      <th>datahoraservidor</th>\n",
       "      <th>geom</th>\n",
       "      <th>dia_da_semana</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134799</td>\n",
       "      <td>C41373</td>\n",
       "      <td>-22.87139</td>\n",
       "      <td>-43.26380</td>\n",
       "      <td>1714043686000</td>\n",
       "      <td>59</td>\n",
       "      <td>315</td>\n",
       "      <td>1714043696000</td>\n",
       "      <td>1714043701000</td>\n",
       "      <td>0101000020E6100000A857CA32C4A145C0BB0F406A13DF...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>POINT (-43.26380 -22.87139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382095</td>\n",
       "      <td>A41322</td>\n",
       "      <td>-22.87830</td>\n",
       "      <td>-43.27721</td>\n",
       "      <td>1714045323000</td>\n",
       "      <td>5</td>\n",
       "      <td>315</td>\n",
       "      <td>1714045332000</td>\n",
       "      <td>1714045335000</td>\n",
       "      <td>0101000020E6100000E40F069E7BA345C0A913D044D8E0...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>POINT (-43.27721 -22.87830)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415238</td>\n",
       "      <td>C41081</td>\n",
       "      <td>-23.02712</td>\n",
       "      <td>-43.48100</td>\n",
       "      <td>1714045553000</td>\n",
       "      <td>14</td>\n",
       "      <td>315</td>\n",
       "      <td>1714045557000</td>\n",
       "      <td>1714045582000</td>\n",
       "      <td>0101000020E610000021B0726891BD45C049111956F106...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>POINT (-43.48100 -23.02712)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>515920</td>\n",
       "      <td>C41395</td>\n",
       "      <td>-22.90483</td>\n",
       "      <td>-43.19300</td>\n",
       "      <td>1714046222000</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>1714046225000</td>\n",
       "      <td>1714046230000</td>\n",
       "      <td>0101000020E610000062105839B49845C08F705AF0A2E7...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>POINT (-43.19300 -22.90483)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710732</td>\n",
       "      <td>C41373</td>\n",
       "      <td>-23.00240</td>\n",
       "      <td>-43.42346</td>\n",
       "      <td>1714075306000</td>\n",
       "      <td>25</td>\n",
       "      <td>315</td>\n",
       "      <td>1714075308000</td>\n",
       "      <td>1714075337000</td>\n",
       "      <td>0101000020E61000000395F1EF33B645C0AA8251499D00...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>POINT (-43.42346 -23.00240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594144</th>\n",
       "      <td>8630235</td>\n",
       "      <td>C41081</td>\n",
       "      <td>-22.87218</td>\n",
       "      <td>-43.25140</td>\n",
       "      <td>1715368048000</td>\n",
       "      <td>35</td>\n",
       "      <td>315</td>\n",
       "      <td>1715368056000</td>\n",
       "      <td>1715368079000</td>\n",
       "      <td>0101000020E6100000711B0DE02DA045C0AC39403047DF...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>POINT (-43.25140 -22.87218)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594145</th>\n",
       "      <td>8451581</td>\n",
       "      <td>C41382</td>\n",
       "      <td>-22.90488</td>\n",
       "      <td>-43.19200</td>\n",
       "      <td>1715352387000</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>1715352392000</td>\n",
       "      <td>1715352407000</td>\n",
       "      <td>0101000020E61000007F6ABC74939845C0F2CD3637A6E7...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>POINT (-43.19200 -22.90488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594146</th>\n",
       "      <td>8833538</td>\n",
       "      <td>C41081</td>\n",
       "      <td>-22.96363</td>\n",
       "      <td>-43.35730</td>\n",
       "      <td>1715369403000</td>\n",
       "      <td>9</td>\n",
       "      <td>315</td>\n",
       "      <td>1715369412000</td>\n",
       "      <td>1715369432000</td>\n",
       "      <td>0101000020E61000002F6EA301BCAD45C0C971A774B0F6...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>POINT (-43.35730 -22.96363)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594147</th>\n",
       "      <td>9010013</td>\n",
       "      <td>C41366</td>\n",
       "      <td>-22.90621</td>\n",
       "      <td>-43.20938</td>\n",
       "      <td>1715370625000</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>1715370635000</td>\n",
       "      <td>1715370662000</td>\n",
       "      <td>0101000020E6100000DF37BEF6CC9A45C0E44EE960FDE7...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>POINT (-43.20938 -22.90621)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594148</th>\n",
       "      <td>10033756</td>\n",
       "      <td>C41247</td>\n",
       "      <td>-23.02572</td>\n",
       "      <td>-43.48131</td>\n",
       "      <td>1715348667000</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>1715348673000</td>\n",
       "      <td>1715348689000</td>\n",
       "      <td>0101000020E61000006F9EEA909BBD45C066DAFE959506...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>POINT (-43.48131 -23.02572)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594149 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   ordem  latitude  longitude       datahora  velocidade  \\\n",
       "0         134799  C41373 -22.87139  -43.26380  1714043686000          59   \n",
       "1         382095  A41322 -22.87830  -43.27721  1714045323000           5   \n",
       "2         415238  C41081 -23.02712  -43.48100  1714045553000          14   \n",
       "3         515920  C41395 -22.90483  -43.19300  1714046222000           0   \n",
       "4         710732  C41373 -23.00240  -43.42346  1714075306000          25   \n",
       "...          ...     ...       ...        ...            ...         ...   \n",
       "594144   8630235  C41081 -22.87218  -43.25140  1715368048000          35   \n",
       "594145   8451581  C41382 -22.90488  -43.19200  1715352387000           1   \n",
       "594146   8833538  C41081 -22.96363  -43.35730  1715369403000           9   \n",
       "594147   9010013  C41366 -22.90621  -43.20938  1715370625000           0   \n",
       "594148  10033756  C41247 -23.02572  -43.48131  1715348667000           0   \n",
       "\n",
       "       linha  datahoraenvio  datahoraservidor  \\\n",
       "0        315  1714043696000     1714043701000   \n",
       "1        315  1714045332000     1714045335000   \n",
       "2        315  1714045557000     1714045582000   \n",
       "3        315  1714046225000     1714046230000   \n",
       "4        315  1714075308000     1714075337000   \n",
       "...      ...            ...               ...   \n",
       "594144   315  1715368056000     1715368079000   \n",
       "594145   315  1715352392000     1715352407000   \n",
       "594146   315  1715369412000     1715369432000   \n",
       "594147   315  1715370635000     1715370662000   \n",
       "594148   315  1715348673000     1715348689000   \n",
       "\n",
       "                                                     geom dia_da_semana  \\\n",
       "0       0101000020E6100000A857CA32C4A145C0BB0F406A13DF...      Thursday   \n",
       "1       0101000020E6100000E40F069E7BA345C0A913D044D8E0...      Thursday   \n",
       "2       0101000020E610000021B0726891BD45C049111956F106...      Thursday   \n",
       "3       0101000020E610000062105839B49845C08F705AF0A2E7...      Thursday   \n",
       "4       0101000020E61000000395F1EF33B645C0AA8251499D00...      Thursday   \n",
       "...                                                   ...           ...   \n",
       "594144  0101000020E6100000711B0DE02DA045C0AC39403047DF...        Friday   \n",
       "594145  0101000020E61000007F6ABC74939845C0F2CD3637A6E7...        Friday   \n",
       "594146  0101000020E61000002F6EA301BCAD45C0C971A774B0F6...        Friday   \n",
       "594147  0101000020E6100000DF37BEF6CC9A45C0E44EE960FDE7...        Friday   \n",
       "594148  0101000020E61000006F9EEA909BBD45C066DAFE959506...        Friday   \n",
       "\n",
       "                           geometry  \n",
       "0       POINT (-43.26380 -22.87139)  \n",
       "1       POINT (-43.27721 -22.87830)  \n",
       "2       POINT (-43.48100 -23.02712)  \n",
       "3       POINT (-43.19300 -22.90483)  \n",
       "4       POINT (-43.42346 -23.00240)  \n",
       "...                             ...  \n",
       "594144  POINT (-43.25140 -22.87218)  \n",
       "594145  POINT (-43.19200 -22.90488)  \n",
       "594146  POINT (-43.35730 -22.96363)  \n",
       "594147  POINT (-43.20938 -22.90621)  \n",
       "594148  POINT (-43.48131 -23.02572)  \n",
       "\n",
       "[594149 rows x 12 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ordem', 'latitude', 'longitude', 'datahora', 'velocidade',\n",
       "       'linha', 'datahoraenvio', 'datahoraservidor', 'geom', 'dia_da_semana'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_grid(min_lat, min_lon, max_lat, max_lon, cell_size=50, crs=\"EPSG:4326\"):\n",
    "# Aproximação para conversão de metros para graus\n",
    "    lat_mid = (min_lat + max_lat) / 2\n",
    "    deg_per_meter_lat = 1 / 111320  # Aproximadamente 111.32 km por grau de latitude\n",
    "    deg_per_meter_lon = 1 / (111320 * np.cos(np.deg2rad(lat_mid)))  # Varia com a latitude\n",
    "\n",
    "    cell_size_deg_lat = cell_size * deg_per_meter_lat\n",
    "    cell_size_deg_lon = cell_size * deg_per_meter_lon\n",
    "\n",
    "    # criar as células em um loop\n",
    "    grid_cells = []\n",
    "    for x0 in np.arange(min_lon, max_lon, cell_size_deg_lon):\n",
    "        for y0 in np.arange(min_lat, max_lat, cell_size_deg_lat):\n",
    "            x1 = x0 + cell_size_deg_lon\n",
    "            y1 = y0 + cell_size_deg_lat\n",
    "            poly = shapely.geometry.box(x0, y0, x1, y1)\n",
    "            grid_cells.append(poly)\n",
    "\n",
    "    cells = gpd.GeoDataFrame(grid_cells, columns=['geometry'], crs=crs)\n",
    "    \n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat, min_lon = -23.082, -43.795\n",
    "max_lat, max_lon = -22.735, -43.099\n",
    "cell_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rio = criar_grid(min_lat, min_lon, max_lat, max_lon, cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rio.to_file(\"grid_rio.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_com_grid(gdf, grid):\n",
    "    # Realizar o join espacial\n",
    "    gdf_joined = gpd.sjoin(gdf, grid, how='inner').drop_duplicates('geometry')\n",
    "    \n",
    "    # Manter apenas as colunas grid_id e geometry\n",
    "    gdf_joined = gdf_joined[['geometry']]\n",
    "    \n",
    "    # Redefinir o índice para garantir que seja único\n",
    "    gdf_joined.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return gdf_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_315 = join_com_grid(gdf, grid_rio)\n",
    "grid_315 = grid_315.reset_index(names='grid_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-43.26380 -22.87139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-43.26372 -22.87177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-43.26385 -22.87177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-43.26358 -22.87178)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-43.26377 -22.87139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>POINT (-43.26394 -22.87179)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>POINT (-43.26370 -22.87174)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>POINT (-43.26364 -22.87139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>POINT (-43.26394 -22.87141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>POINT (-43.26350 -22.87138)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id                     geometry\n",
       "0        0  POINT (-43.26380 -22.87139)\n",
       "1        1  POINT (-43.26372 -22.87177)\n",
       "2        2  POINT (-43.26385 -22.87177)\n",
       "3        3  POINT (-43.26358 -22.87178)\n",
       "4        4  POINT (-43.26377 -22.87139)\n",
       "5        5  POINT (-43.26394 -22.87179)\n",
       "6        6  POINT (-43.26370 -22.87174)\n",
       "7        7  POINT (-43.26364 -22.87139)\n",
       "8        8  POINT (-43.26394 -22.87141)\n",
       "9        9  POINT (-43.26350 -22.87138)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_315.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_estatisticas(pontos_gdf, grid_gdf):\n",
    "    pontos_na_grid = gpd.sjoin(pontos_gdf, grid_gdf, how='inner', op='within')\n",
    "    contagem_pontos = pontos_na_grid.groupby('grid_id').size().reset_index(name='contagem_pontos')\n",
    "    centroide_pontos = pontos_na_grid.groupby('grid_id').apply(lambda x: x.geometry.unary_union.centroid).reset_index(name='centroide_pontos')\n",
    "    pontos_na_grid['hora'] = pd.to_datetime(pontos_na_grid['datahoraservidor'], unit='ms').dt.hour\n",
    "    media_hora_pontos = pontos_na_grid.groupby('grid_id')['hora'].mean().reset_index(name='media_hora')\n",
    "    estatisticas_grid = grid_gdf.merge(contagem_pontos, on='grid_id', how='left').merge(media_hora_pontos, on='grid_id', how='left').merge(centroide_pontos, on='grid_id', how='left')\n",
    "    return estatisticas_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/savio/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "estatisticas_grid = calcular_estatisticas(gdf, grid_315)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
